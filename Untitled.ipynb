{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "849fce2c-23b1-4164-9f9d-c67385286b6a",
   "metadata": {},
   "source": [
    "學號:110302005 姓名:江政達\n",
    "選擇比賽:Natural Language Processing with Disaster Tweets\n",
    "比賽簡介:分析推文描述的是否為一真實發生的災害\n",
    "選擇此比賽的原因:現在網路上資訊過多，有時候只靠關鍵字很難找到所需的資訊，所以想透過這個比賽嘗試看看透過文字分析判斷狀況是否屬實\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac125599-2da3-4990-aa66-9cfdd223c85b",
   "metadata": {},
   "source": [
    "導入模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a3ae0f8-8bf6-4fa3-91d7-b674fae0ae54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dcef39-0e74-4390-a389-95c23169b6ed",
   "metadata": {},
   "source": [
    "導入資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "932f523b-4aaf-4066-a6c7-decddb9910e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "train_df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9519565d-9260-4c3a-931f-87c7662540b9",
   "metadata": {},
   "source": [
    "觀察"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d18377c6-271b-4659-8d9d-75eeebb0f0a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3263 entries, 0 to 3262\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        3263 non-null   int64 \n",
      " 1   keyword   3237 non-null   object\n",
      " 2   location  2158 non-null   object\n",
      " 3   text      3263 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 102.1+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id             0\n",
       "keyword       61\n",
       "location    2533\n",
       "text           0\n",
       "target         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()\n",
    "test_df.info()\n",
    "train_df.head()\n",
    "train_df.info()\n",
    "test_df.isnull().sum()\n",
    "train_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3a4f20-b7d5-4e17-a26f-d95531f3079e",
   "metadata": {},
   "source": [
    "刪除遺失過多的資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2dfc44e-e81c-4e65-adbb-a93acb5f6206",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.drop([\"keyword\",\"location\"],axis = 1, inplace = True)\n",
    "train_df.drop([\"keyword\",\"location\"],axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7864572-6e54-4c3f-a09e-054abc34efba",
   "metadata": {},
   "source": [
    "資料清理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696480f6-9a59-496e-8eb4-8f27b147a9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n",
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ff3cf135c84db785a9a3a9e4acf90c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ed4e98091b43408ba931029013a52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06aedc1db6e94606882e91ea1365cb62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4468670d3f2c4f90a57f705bf2860b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84380ccdb4c44a0eb310319104230675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7613 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>23</td>\n",
       "      <td>Whats up man</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>24</td>\n",
       "      <td>I love fruits</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>25</td>\n",
       "      <td>Summer is lovely</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>26</td>\n",
       "      <td>My car is so fast</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>28</td>\n",
       "      <td>What a goooooooaaaaaal</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7581</th>\n",
       "      <td>10833</td>\n",
       "      <td>engineshed Great atmosphere at the British Lio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7582</th>\n",
       "      <td>10834</td>\n",
       "      <td>Cramer Igers 3 words that wrecked Disneys stoc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7584</th>\n",
       "      <td>10837</td>\n",
       "      <td>These boxes are ready to explode Exploding Kit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7587</th>\n",
       "      <td>10841</td>\n",
       "      <td>Sirens everywhere</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7593</th>\n",
       "      <td>10848</td>\n",
       "      <td>I just heard a really loud bang and everyone i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4342 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               text  target\n",
       "15       23                                       Whats up man       0\n",
       "16       24                                      I love fruits       0\n",
       "17       25                                   Summer is lovely       0\n",
       "18       26                                  My car is so fast       0\n",
       "19       28                             What a goooooooaaaaaal       0\n",
       "...     ...                                                ...     ...\n",
       "7581  10833  engineshed Great atmosphere at the British Lio...       0\n",
       "7582  10834  Cramer Igers 3 words that wrecked Disneys stoc...       0\n",
       "7584  10837  These boxes are ready to explode Exploding Kit...       0\n",
       "7587  10841                                  Sirens everywhere       0\n",
       "7593  10848  I just heard a really loud bang and everyone i...       0\n",
       "\n",
       "[4342 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import text_hammer as th\n",
    "from tqdm._tqdm_notebook import tqdm_notebook \n",
    "\n",
    "\n",
    "def text_preprocessing(df,col_name):\n",
    "    column = col_name\n",
    "    df[column] = df[column].progress_apply(lambda x :str(x))\n",
    "    df[column] = df[column].progress_apply(lambda x :th.remove_emails(x))\n",
    "    df[column] = df[column].progress_apply(lambda x :th.remove_html_tags(x))\n",
    "    df[column] = df[column].progress_apply(lambda x :th.remove_special_chars(x))\n",
    "    df[column] = df[column].progress_apply(lambda x :th.remove_accented_chars(x))\n",
    "    \n",
    "    return(df)\n",
    "\n",
    "train_cleaned_df = text_preprocessing(train_df,'text')\n",
    "train_cleaned_df[train_cleaned_df.target == 0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a41ef3c-b220-41e7-842a-84121d670d72",
   "metadata": {},
   "source": [
    "標記資料並建模"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6205f38f-0869-4c27-a77e-158cacc3dc45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at bert-large-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n",
      "- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at bert-large-uncased.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer,TFBertModel\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-large-uncased')\n",
    "bert = TFBertModel.from_pretrained('bert-large-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f912616c-fa24-4272-9359-a5d0cd4b8acf",
   "metadata": {},
   "source": [
    "找出推文的最多單字量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8c6bc2a-e3c2-4323-a487-15484b2c3ae0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len of tweets 31\n"
     ]
    }
   ],
   "source": [
    "print(\"max len of tweets\",max([len(x.split()) for x in train_df.text]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd95c9-b375-46d8-a5c4-c67091bc9268",
   "metadata": {},
   "source": [
    "train文字轉換為bert格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e19fb07e-46f9-4f09-acff-58d88fc6bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tokenizer(\n",
    "    text = train_cleaned_df.text.tolist(),\n",
    "    add_special_tokens = True,\n",
    "    max_length = 35,\n",
    "    truncation = True, #超過35單字刪除\n",
    "    padding = True,  #不足35單字補0\n",
    "    return_tensors = \"tf\",\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)\n",
    "\n",
    "y_train = train_cleaned_df.target.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "774a6018-068d-4ab8-a840-377147f8f8dc",
   "metadata": {},
   "source": [
    "導入模型模組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d8b0aa5-80d0-4e7c-869d-731d41ccef43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy,BinaryCrossentropy\n",
    "from tensorflow.keras.metrics import CategoricalAccuracy,BinaryAccuracy\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6dbaef-8da5-44f1-a925-02a050a7a226",
   "metadata": {},
   "source": [
    "構建模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2de5d808-5d75-4eb4-95a0-4113d47c7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 35\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "\n",
    "input_ids = Input(shape=(max_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "input_mask = Input(shape=(max_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "\n",
    "embeddings = bert([input_ids,input_mask])[1]\n",
    "\n",
    "out = tf.keras.layers.Dropout(0.1)(embeddings)\n",
    "out = Dense(128, activation='relu')(out)\n",
    "out = tf.keras.layers.Dropout(0.1)(out)\n",
    "out = Dense(32,activation = 'relu')(out)\n",
    "\n",
    "y = Dense(1,activation = 'sigmoid')(out)\n",
    "\n",
    "model = tf.keras.Model(inputs=[input_ids, input_mask], outputs=y)\n",
    "model.layers[2].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f9cd7ab-529d-4675-a42d-26b2d5d2b30a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 35)]         0           []                               \n",
      "                                                                                                  \n",
      " attention_mask (InputLayer)    [(None, 35)]         0           []                               \n",
      "                                                                                                  \n",
      " tf_bert_model_1 (TFBertModel)  TFBaseModelOutputWi  335141888   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_mask[0][0]']         \n",
      "                                tentions(last_hidde                                               \n",
      "                                n_state=(None, 35,                                                \n",
      "                                1024),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 1024),                                                         \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " dropout_146 (Dropout)          (None, 1024)         0           ['tf_bert_model_1[0][1]']        \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          131200      ['dropout_146[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_147 (Dropout)          (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 32)           4128        ['dropout_147[0][0]']            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1)            33          ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 335,277,249\n",
      "Trainable params: 335,277,249\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505c51b8-bfa6-484d-8dab-3843482cd466",
   "metadata": {},
   "source": [
    "編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c866183f-e2ab-4663-8403-2f8a024060ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.legacy.Adam(\n",
    "    learning_rate=6e-06, \n",
    "    epsilon=1e-08,\n",
    "    decay=0.01,\n",
    "    clipnorm=1.0)\n",
    "\n",
    "loss = BinaryCrossentropy(from_logits = True)\n",
    "metric = BinaryAccuracy('accuracy'),\n",
    "\n",
    "model.compile(\n",
    "    optimizer = optimizer,\n",
    "    loss = loss, \n",
    "    metrics = metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cffe83-21f8-4201-a6a7-61ea48d7b745",
   "metadata": {},
   "source": [
    "訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a30a411b-24dd-4f13-a4c5-9305f356defa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\backend.py:5703: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254/254 [==============================] - 2607s 10s/step - loss: 0.5452 - accuracy: 0.7424 - val_loss: 0.4495 - val_accuracy: 0.8102\n"
     ]
    }
   ],
   "source": [
    "train_history = model.fit(\n",
    "    x ={'input_ids':x_train['input_ids'],'attention_mask':x_train['attention_mask']} ,\n",
    "    y = y_train,\n",
    "    validation_split = 0.2,\n",
    "    epochs=1, \n",
    "    batch_size=24\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6bb929b9-4adf-42b2-b14b-050cad35dcc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3c35055a3f40b2a416c0cf464d32fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2260971101405283b2a4800a0149f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38bad6685b09428aa0046538a3a5552a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db92d4f9c284f58a8309bde7b832fba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75d13e313924e81b929193929ed1452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3263 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_cleaned_df = text_preprocessing(test_df,'text')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9542de-cf35-4a3d-b9e0-71acc39e67a2",
   "metadata": {},
   "source": [
    "test文字轉bert格式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "08928842-9254-4551-8389-c867910a657d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tokenizer(\n",
    "    text=test_cleaned_df.text.tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=35,\n",
    "    truncation=True,\n",
    "    padding=True, \n",
    "    return_tensors='tf',\n",
    "    return_token_type_ids = False,\n",
    "    return_attention_mask = True,\n",
    "    verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "151020d3-7603-40f4-a9ee-17675f979e66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102/102 [==============================] - 317s 3s/step\n"
     ]
    }
   ],
   "source": [
    "predicted = model.predict({'input_ids':x_test['input_ids'],'attention_mask':x_test['attention_mask']})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c00ff93-6145-4cf6-8cf3-e567578458d7",
   "metadata": {},
   "source": [
    "預測值>0.5改為1，其餘為0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "70f673e7-0db8-4589-91a2-71255c0f462e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predicted = np.where(predicted>0.5,1,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a87d79-2635-437e-97f7-6e45b4c99546",
   "metadata": {},
   "source": [
    "匯出結果\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6f72ee62-9c94-42e9-bd2e-80b7655429be",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv(\"sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a5bf0a2e-18d8-4399-b7f0-8ddadac180cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df['id'] = test_df.id\n",
    "sample_df['target'] = y_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd7c4e9c-319a-40c4-b19f-17c16138f42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('1.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baf802a-a10c-45e8-9146-055c9249f90b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
